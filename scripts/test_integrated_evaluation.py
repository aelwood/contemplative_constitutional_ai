#!/usr/bin/env python3
"""
Test script for the integrated Contemplative Constitutional AI Evaluation Framework.
Demonstrates usage with both local models (using existing ModelLoader) and API models.
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))


def test_model_wrapper_integration():
    """Test the integration between ModelWrapper and ModelLoader."""
    print("üß™ Testing ModelWrapper Integration with ModelLoader")
    print("=" * 60)
    
    try:
        from models.model_wrapper import ModelWrapperFactory
        from models.model_loader import ModelLoader
        
        print("‚úÖ Successfully imported ModelWrapper and ModelLoader")
        
        # Test ModelLoader
        model_loader = ModelLoader()
        device = model_loader.detect_device()
        print(f"‚úÖ ModelLoader detected device: {device}")
        
        # Test model info retrieval
        try:
            model_info = model_loader.get_model_info('qwen2_0_5b')
            print(f"‚úÖ Retrieved model info for qwen2_0_5b: {model_info['model_name']}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not retrieve model info: {e}")
        
        # Test ModelWrapperFactory with local model
        try:
            wrapper = ModelWrapperFactory.create_from_model_loader('qwen2_0_5b')
            print(f"‚úÖ Created LocalModelWrapper for qwen2_0_5b")
            print(f"   - Model name: {wrapper.model_name}")
            print(f"   - Model type: {wrapper.model_type}")
            print(f"   - Device: {wrapper.device}")
            print(f"   - Max memory: {wrapper.max_memory_gb}GB")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not create LocalModelWrapper: {e}")
        
        # Test ModelWrapperFactory with evaluation config
        try:
            wrapper = ModelWrapperFactory.create_from_config_file(
                "configs/evaluation_configs.yaml", 
                "claude_3_5_sonnet"
            )
            print(f"‚úÖ Created AnthropicModelWrapper for claude_3_5_sonnet")
            print(f"   - Model name: {wrapper.model_name}")
            print(f"   - Model type: {wrapper.model_type}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Could not create AnthropicModelWrapper: {e}")
        
        print("\nüéØ Integration Test Results:")
        print("=" * 40)
        print("‚úÖ ModelWrapper successfully integrates with ModelLoader")
        print("‚úÖ Local models use existing model_configs.yaml")
        print("‚úÖ API models use evaluation_configs.yaml")
        print("‚úÖ Consistent interface for both model types")
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        return False
    
    return True


def demonstrate_evaluation_usage():
    """Demonstrate how to use the integrated evaluation framework."""
    print("\nüî¨ Integrated Evaluation Framework Usage")
    print("=" * 60)
    
    print("\nüìã Available Commands:")
    print("=" * 30)
    
    print("\n1. Evaluate local model (using existing ModelLoader):")
    print("python scripts/evaluate_contemplative.py \\")
    print("    --baseline-model qwen2_0_5b \\")
    print("    --dataset test_prompts \\")
    print("    --max-prompts 5 \\")
    print("    --verbose")
    
    print("\n2. Compare local models:")
    print("python scripts/evaluate_contemplative.py \\")
    print("    --baseline-model qwen2_0_5b \\")
    print("    --finetuned-model qwen2_5_7b \\")
    print("    --dataset test_prompts \\")
    print("    --max-prompts 5 \\")
    print("    --verbose")
    
    print("\n3. Compare local vs API model:")
    print("export ANTHROPIC_API_KEY='your-key'")
    print("python scripts/evaluate_contemplative.py \\")
    print("    --baseline-model qwen2_0_5b \\")
    print("    --finetuned-model claude_3_5_sonnet \\")
    print("    --dataset test_prompts \\")
    print("    --max-prompts 5 \\")
    print("    --verbose")
    
    print("\n4. Use existing model configuration:")
    print("python scripts/evaluate_contemplative.py \\")
    print("    --config configs/model_configs.yaml \\")
    print("    --baseline-model qwen2_0_5b \\")
    print("    --dataset test_prompts \\")
    print("    --verbose")
    
    print("\nüîß Key Integration Features:")
    print("=" * 40)
    print("‚úÖ Local models use existing ModelLoader configuration")
    print("‚úÖ API models use evaluation-specific configuration")
    print("‚úÖ Consistent interface for both model types")
    print("‚úÖ Automatic device detection and memory management")
    print("‚úÖ Support for quantization and fine-tuned models")
    print("‚úÖ Unified evaluation metrics across model types")
    
    print("\nüìä Evaluation Metrics:")
    print("=" * 30)
    print("Contemplative Principles:")
    print("  - Emptiness: Non-absolute, interdependent language")
    print("  - Non-duality: Multiple perspectives, synthesis")
    print("  - Mindfulness: Present awareness, uncertainty acknowledgment")
    print("  - Compassion: Universal care, harm reduction")
    
    print("\nSafety Metrics:")
    print("  - Harmfulness: Lower is better")
    print("  - Bias Mitigation: Lower is better")
    print("  - Refusal Clarity: Higher is better")
    print("  - Uncertainty Acknowledgment: Higher is better")
    
    print("\nHelpfulness:")
    print("  - Relevance: Response addresses the prompt")
    print("  - Completeness: Response is complete and actionable")
    print("  - Clarity: Response is clear and understandable")


def main():
    print("üß™ Contemplative Constitutional AI - Integrated Evaluation Framework Test")
    print("=" * 80)
    
    # Test integration
    integration_success = test_model_wrapper_integration()
    
    if integration_success:
        print("\n‚úÖ Integration test passed!")
        demonstrate_evaluation_usage()
        
        print("\nüöÄ Next Steps:")
        print("=" * 40)
        print("1. Install API dependencies (optional):")
        print("   pip install anthropic openai google-generativeai")
        print("\n2. Set API keys (if using API models):")
        print("   export ANTHROPIC_API_KEY='your-key'")
        print("   export OPENAI_API_KEY='your-key'")
        print("   export GOOGLE_API_KEY='your-key'")
        print("\n3. Run evaluation commands above")
        print("\n4. Analyze results and iterate on model training")
        
        print("\n‚úÖ Integrated evaluation framework ready!")
        print("üîß Local models: Use existing model_configs.yaml")
        print("üåê API models: Use evaluation_configs.yaml")
        print("üìä Unified evaluation: Same metrics for all models")
    else:
        print("\n‚ùå Integration test failed!")
        print("Please check the error messages above and fix any issues.")


if __name__ == "__main__":
    main()
