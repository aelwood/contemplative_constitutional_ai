{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Generation: Constitutional Preference Pairs\n",
        "\n",
        "This notebook generates preference pairs for training Constitutional AI models.\n",
        "\n",
        "## What it does:\n",
        "1. Loads prompts from AILuminate benchmark\n",
        "2. Generates baseline responses using a base model\n",
        "3. Critiques responses using contemplative principles\n",
        "4. Generates revised responses\n",
        "5. Creates preference pairs (rejected vs chosen)\n",
        "6. Creates train/test splits\n",
        "7. Syncs results to S3\n",
        "\n",
        "## Parameters to configure:\n",
        "- Number of prompts\n",
        "- Hazard categories to include\n",
        "- Model to use for generation\n",
        "- Constitution file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import yaml\n",
        "\n",
        "# Setup\n",
        "os.chdir('..')\n",
        "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
        "\n",
        "with open('configs/sagemaker_configs.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "S3_BUCKET = config['s3']['bucket']\n",
        "print(f\"Working directory: {os.getcwd()}\")\n",
        "print(f\"S3 Bucket: {S3_BUCKET}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Adjust these parameters based on your needs:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generation Configuration\n",
        "CONFIG = {\n",
        "    # Data source\n",
        "    'max_prompts': 100,  # Number of prompts to process (100 prompts = 400 pairs with 4 principles)\n",
        "    'hazard_categories': ['vcr', 'cse', 'hte', 'ssh'],  # AILuminate hazard types\n",
        "    'persona_types': None,  # None = all persona types\n",
        "    \n",
        "    # Model settings\n",
        "    'model': 'qwen2_7b',  # Options: qwen2_0_5b, qwen2_1_5b, qwen2_7b\n",
        "    'device': 'cuda',\n",
        "    'max_memory_gb': 20.0,\n",
        "    \n",
        "    # Constitution\n",
        "    'constitution': 'data/constitutions/contemplative_principles.md',\n",
        "    'principles': None,  # None = use all principles\n",
        "    \n",
        "    # Output\n",
        "    'output_file': 'results/preference_pairs_100.jsonl',\n",
        "    'split_config': 'data/splits/default_split.json',\n",
        "    'test_size': 0.1,  # 10% for test set\n",
        "}\n",
        "\n",
        "# Print configuration\n",
        "print(\"Data Generation Configuration:\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Preference Pairs\n",
        "\n",
        "This will take some time depending on the number of prompts and model size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build command\n",
        "cmd_parts = [\n",
        "    \"python scripts/generate_cai_data.py\",\n",
        "    \"--use-ailuminate\",\n",
        "    f\"--constitution {CONFIG['constitution']}\",\n",
        "    f\"--model {CONFIG['model']}\",\n",
        "    f\"--max-prompts {CONFIG['max_prompts']}\",\n",
        "    f\"--device {CONFIG['device']}\",\n",
        "    f\"--max-memory-gb {CONFIG['max_memory_gb']}\",\n",
        "    f\"--output {CONFIG['output_file']}\",\n",
        "    \"--create-split\",\n",
        "    f\"--test-size {CONFIG['test_size']}\",\n",
        "    f\"--split-config {CONFIG['split_config']}\",\n",
        "]\n",
        "\n",
        "if CONFIG['hazard_categories']:\n",
        "    cmd_parts.append(f\"--hazard-categories {' '.join(CONFIG['hazard_categories'])}\")\n",
        "\n",
        "if CONFIG['persona_types']:\n",
        "    cmd_parts.append(f\"--persona-types {' '.join(CONFIG['persona_types'])}\")\n",
        "\n",
        "if CONFIG['principles']:\n",
        "    cmd_parts.append(f\"--principles {' '.join(CONFIG['principles'])}\")\n",
        "\n",
        "command = \" \\\\\\n    \".join(cmd_parts)\n",
        "print(\"Running command:\")\n",
        "print(command)\n",
        "print(\"\\n\" + \"=\"*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute generation\n",
        "!{command}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analyze Generated Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "\n",
        "# Load generated pairs\n",
        "pairs = []\n",
        "output_path = Path(CONFIG['output_file'])\n",
        "if output_path.exists():\n",
        "    with open(output_path, 'r') as f:\n",
        "        for line in f:\n",
        "            pairs.append(json.loads(line))\n",
        "\n",
        "print(f\"Generated {len(pairs)} preference pairs\")\n",
        "\n",
        "# Analyze by principle\n",
        "principles = [p['principle'] for p in pairs]\n",
        "principle_counts = Counter(principles)\n",
        "print(f\"\\nBreakdown by principle:\")\n",
        "for principle, count in principle_counts.items():\n",
        "    print(f\"  {principle}: {count}\")\n",
        "\n",
        "# Show examples\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Example Preference Pair:\")\n",
        "print(f\"{'='*60}\")\n",
        "if pairs:\n",
        "    example = pairs[0]\n",
        "    print(f\"\\nPrinciple: {example['principle']}\")\n",
        "    print(f\"\\nPrompt:\\n{example['prompt'][:300]}...\")\n",
        "    print(f\"\\nRejected Response:\\n{example['rejected'][:300]}...\")\n",
        "    print(f\"\\nChosen Response:\\n{example['chosen'][:300]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Train/Test Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load split configuration\n",
        "split_path = Path(CONFIG['split_config'])\n",
        "if split_path.exists():\n",
        "    with open(split_path, 'r') as f:\n",
        "        split_info = json.load(f)\n",
        "    \n",
        "    print(\"Train/Test Split Information:\")\n",
        "    print(f\"  Total prompts: {split_info['n_prompts']}\")\n",
        "    print(f\"  Train prompts: {len(split_info['train_prompt_ids'])}\")\n",
        "    print(f\"  Test prompts: {len(split_info['test_prompt_ids'])}\")\n",
        "    print(f\"  Test size: {split_info['test_size']}\")\n",
        "    print(f\"  Random seed: {split_info['random_state']}\")\n",
        "    print(f\"\\nWith {len(principle_counts)} principles per prompt:\")\n",
        "    print(f\"  Expected train pairs: {len(split_info['train_prompt_ids']) * len(principle_counts)}\")\n",
        "    print(f\"  Expected test pairs: {len(split_info['test_prompt_ids']) * len(principle_counts)}\")\n",
        "else:\n",
        "    print(f\"Split configuration not found at {split_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sync to S3\n",
        "\n",
        "Save the generated data to S3 for persistence and sharing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.sagemaker_utils import sync_to_s3\n",
        "\n",
        "if S3_BUCKET != \"your-bucket-contemplative-ai\":\n",
        "    print(\"Syncing results to S3...\")\n",
        "    \n",
        "    # Sync preference pairs\n",
        "    output_filename = Path(CONFIG['output_file']).name\n",
        "    s3_data_path = f\"s3://{S3_BUCKET}/results/preference_pairs/{output_filename}\"\n",
        "    success = sync_to_s3(CONFIG['output_file'], s3_data_path)\n",
        "    \n",
        "    # Sync split configuration\n",
        "    split_filename = Path(CONFIG['split_config']).name\n",
        "    s3_split_path = f\"s3://{S3_BUCKET}/data/splits/{split_filename}\"\n",
        "    success = sync_to_s3(CONFIG['split_config'], s3_split_path) and success\n",
        "    \n",
        "    if success:\n",
        "        print(f\"\\n✅ Results synced to S3:\")\n",
        "        print(f\"   Data: {s3_data_path}\")\n",
        "        print(f\"   Split: {s3_split_path}\")\n",
        "    else:\n",
        "        print(\"\\n⚠️ Some files failed to sync\")\n",
        "else:\n",
        "    print(\"⚠️ Skipping S3 sync - configure bucket in configs/sagemaker_configs.yaml\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "✅ Data generation complete!\n",
        "\n",
        "### Generated Files:\n",
        "- **Preference pairs**: `{CONFIG['output_file']}`\n",
        "- **Split config**: `{CONFIG['split_config']}`\n",
        "\n",
        "### Next Steps:\n",
        "1. Review the generated pairs above\n",
        "2. Use `02_training.ipynb` to train a model with this data\n",
        "3. Or generate more data with different settings by rerunning this notebook\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
