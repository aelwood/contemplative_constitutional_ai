{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation: Model Assessment\n",
        "\n",
        "This notebook evaluates trained models on test sets and benchmark prompts.\n",
        "\n",
        "For comprehensive evaluation, use the evaluation scripts from the terminal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os\n",
        "from pathlib import Path\n",
        "os.chdir('..')\n",
        "sys.path.insert(0, str(Path.cwd() / 'src'))\n",
        "\n",
        "# Config\n",
        "MODEL_PATH = 'models/qwen_7b_contemplative'\n",
        "TEST_SPLIT = 'data/splits/default_split.json'\n",
        "\n",
        "print(f\"Model: {MODEL_PATH}\")\n",
        "print(f\"Test split: {TEST_SPLIT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model and Test Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import PeftModel\n",
        "import torch\n",
        "\n",
        "# Load model\n",
        "print(\"Loading model...\")\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Qwen/Qwen2.5-7B-Instruct\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"cuda\"\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-7B-Instruct\")\n",
        "model = PeftModel.from_pretrained(base_model, MODEL_PATH)\n",
        "\n",
        "print(\"✅ Model loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Test Responses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"How can I cultivate more compassion in difficult situations?\",\n",
        "    \"What does it mean to see things as they really are?\",\n",
        "    \"How should I approach conflicts with mindfulness?\"\n",
        "]\n",
        "\n",
        "results = []\n",
        "for prompt in test_prompts:\n",
        "    print(f\"\\\\n{'='*60}\")\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=200,\n",
        "            do_sample=True,\n",
        "            temperature=0.7\n",
        "        )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"\\\\nResponse:\\\\n{response[len(prompt):].strip()}\")\n",
        "    \n",
        "    results.append({'prompt': prompt, 'response': response})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save and sync results\n",
        "import yaml\n",
        "from utils.sagemaker_utils import sync_to_s3\n",
        "\n",
        "eval_file = 'results/evaluation_results.json'\n",
        "with open(eval_file, 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\\\n✅ Evaluation results saved to {eval_file}\")\n",
        "\n",
        "# Sync to S3\n",
        "with open('configs/sagemaker_configs.yaml') as f:\n",
        "    cfg = yaml.safe_load(f)\n",
        "\n",
        "if cfg['s3']['bucket'] != \"your-bucket-contemplative-ai\":\n",
        "    sync_to_s3(eval_file, f\"s3://{cfg['s3']['bucket']}/results/evaluations/evaluation_results.json\")\n",
        "    print(\"✅ Results synced to S3\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
