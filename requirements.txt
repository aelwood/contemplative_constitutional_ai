# Contemplative Constitutional AI - Requirements
# Optimized for Apple Silicon (MacBook M2) and cloud GPUs

# Core ML libraries with Apple Silicon support
torch>=2.2,<2.6
# torchvision>=0.17,<0.20  # Commented out - causes lzma import issues and not needed for text models
torchaudio>=2.2,<2.6

# Transformers and related libraries
transformers>=4.43,<5.0
accelerate>=0.25,<1.0
datasets>=2.18,<3.0
tokenizers>=0.15,<1.0
sentencepiece>=0.2.0,<1.0

# Training libraries
peft>=0.8,<1.0          # Parameter-Efficient Fine-Tuning
trl>=0.7,<1.0           # Transformer Reinforcement Learning (DPO)
bitsandbytes>=0.42,<1.0 # Quantization support

# Data processing
pandas>=2.0,<3.0
numpy>=1.24,<2.0
scipy>=1.10,<2.0
scikit-learn>=1.3,<2.0

# Evaluation and metrics
evaluate>=0.4,<1.0
rouge-score>=0.1,<1.0
sacrebleu>=2.3,<3.0

# Utilities
psutil>=5.9,<6.0        # System monitoring
tqdm>=4.65,<5.0         # Progress bars
requests>=2.28,<3.0     # HTTP requests
tiktoken>=0.5,<1.0      # OpenAI tokenizer

# Configuration and logging
pyyaml>=6.0,<7.0
python-dotenv>=1.0,<2.0

# Optional: Experiment tracking (uncomment if needed)
# wandb>=0.16,<1.0
# tensorboard>=2.14,<3.0

# Optional: Additional safety/evaluation tools
# perspective-api>=0.1,<1.0

# Development tools
jupyter>=1.0,<2.0
ipywidgets>=8.0,<9.0

# Note: For production GPU environments, you may need:
# - Different torch versions with CUDA support
# - Additional distributed training libraries
# - Cloud-specific authentication libraries
